{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f541c8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20abfd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28 * 28)).astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b2394a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDense:\n",
    "    def __init__(self, n_in, n_out, activation):\n",
    "        self.activation = activation\n",
    "        w_shape = (n_in, n_out)\n",
    "        self.w = tf.Variable(tf.random.uniform(w_shape, minval=0, maxval=1e-1))\n",
    "        b_shape = (n_out,)\n",
    "        self.b = tf.Variable(tf.zeros(b_shape))\n",
    "    def __call__(self, x):\n",
    "        return self.activation(tf.matmul(x, self.w) + self.b)\n",
    "    @property\n",
    "    def weights(self):\n",
    "        return [self.w, self.b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9e28b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = SimpleDense(100,10,lambda x: x)\n",
    "assert d(tf.Variable(tf.random.uniform((5,100)))).shape == [5,10]\n",
    "assert len(d.weights) == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3280a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleSequential:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    @property\n",
    "    def weights(self):\n",
    "#         return [weights for layer_weights in [layer.weights for layer in s.layers] for weights in layer_weights]\n",
    "        weights = []\n",
    "        for layer in self.layers:\n",
    "            weights += layer.weights\n",
    "        return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74698710",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = SimpleSequential([SimpleDense(10,5,lambda x: x), SimpleDense(5,2,lambda x: x)])\n",
    "assert len(s.weights) == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31a8b412",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleSequential([\n",
    "    SimpleDense(28*28,512,tf.nn.relu), \n",
    "    SimpleDense(512,10,tf.nn.softmax)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8907be15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchGenerator:\n",
    "    def __init__(self, images, labels, bs=128):\n",
    "        assert len(images)==len(labels)\n",
    "        self.images, self.labels, self.bs = images, labels, bs\n",
    "        self.i = 0\n",
    "        self.n_batches = math.ceil(len(images)/bs)\n",
    "    def next(self):\n",
    "        if self.i >= len(self.images):\n",
    "            self.i = 0\n",
    "            shuffled_indexes = np.random.permutation(range(len(self.images)))\n",
    "            self.images, self.labels = self.images[shuffled_indexes], self.labels[shuffled_indexes]\n",
    "        images, labels = [o[self.i : self.i+self.bs] for o in [self.images, self.labels]]\n",
    "        self.i += self.bs\n",
    "        return images, labels        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "019bd33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_gen = BatchGenerator(test_images, test_labels)\n",
    "first_batch = batch_gen.next()\n",
    "assert first_batch[1].shape == (128,)\n",
    "for i in range(batch_gen.n_batches-2): batch_gen.next()\n",
    "last_batch = batch_gen.next()\n",
    "assert last_batch[1].shape == (16,)\n",
    "assert batch_gen.i == 10112\n",
    "first_batch_again = batch_gen.next()\n",
    "assert first_batch[1].shape == (128,)\n",
    "assert batch_gen.i == 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5683afa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b112426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((['a0', 'a1'], [0, 1]), 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images, labels = [f'a{i}' for i in range(10)], list(range(10))\n",
    "batch_gen = BatchGenerator(images, labels, 2)\n",
    "batch_gen.next(), batch_gen.i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2585407",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_gen = BatchGenerator(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c4f9ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(128, 10), dtype=float32, numpy=\n",
       "array([[7.7961124e-02, 8.3780307e-01, 1.2872348e-03, ..., 1.5569431e-02,\n",
       "        2.6265509e-06, 3.2489405e-07],\n",
       "       [6.0034063e-02, 8.8943893e-01, 5.1579502e-04, ..., 9.6332002e-03,\n",
       "        3.6768196e-07, 6.2927931e-08],\n",
       "       [1.5948652e-01, 6.4298207e-01, 6.7167785e-03, ..., 4.1663308e-02,\n",
       "        6.4725791e-05, 2.2078531e-05],\n",
       "       ...,\n",
       "       [8.5260063e-02, 8.1263644e-01, 1.9896722e-03, ..., 1.9133260e-02,\n",
       "        3.2622779e-06, 6.6956204e-07],\n",
       "       [6.8221211e-02, 8.6073768e-01, 1.2657690e-03, ..., 1.4047344e-02,\n",
       "        1.3826368e-06, 2.7396595e-07],\n",
       "       [1.2595120e-01, 7.0753396e-01, 3.7248274e-03, ..., 2.8168768e-02,\n",
       "        1.8573486e-05, 3.9177071e-06]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(batch_gen.next()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef6249bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_training_step(model, images_batch, labels_batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images_batch)\n",
    "        per_sample_losses = tf.keras.losses.sparse_categorical_crossentropy(labels_batch, predictions)\n",
    "        average_loss = tf.reduce_mean(per_sample_losses)\n",
    "    gradients = tape.gradient(average_loss, model.weights)\n",
    "    update_weights(gradients, model.weights)\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12dbc53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rate = 1e-3\n",
    "\n",
    "# def update_weights(gradients, weights):\n",
    "#     for g, w in zip(gradients, weights):\n",
    "#         w.assign_sub(g * learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cba0632d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "optim = optimizers.SGD(1e-3)\n",
    "\n",
    "def update_weights(gradients, weights):\n",
    "    optim.apply_gradients(zip(gradients, weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b90de604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=5.7799664>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ib, lb = batch_gen.next()\n",
    "one_training_step(model, ib, lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9908f093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "0 average_loss tf.Tensor(8.067356, shape=(), dtype=float32)\n",
      "100 average_loss tf.Tensor(2.1875548, shape=(), dtype=float32)\n",
      "200 average_loss tf.Tensor(2.1630116, shape=(), dtype=float32)\n",
      "300 average_loss tf.Tensor(2.0339882, shape=(), dtype=float32)\n",
      "400 average_loss tf.Tensor(2.1619883, shape=(), dtype=float32)\n",
      "epoch 1\n",
      "0 average_loss tf.Tensor(1.9044305, shape=(), dtype=float32)\n",
      "100 average_loss tf.Tensor(1.8781254, shape=(), dtype=float32)\n",
      "200 average_loss tf.Tensor(1.9063525, shape=(), dtype=float32)\n",
      "300 average_loss tf.Tensor(1.7369076, shape=(), dtype=float32)\n",
      "400 average_loss tf.Tensor(1.6588811, shape=(), dtype=float32)\n",
      "epoch 2\n",
      "0 average_loss tf.Tensor(1.9068744, shape=(), dtype=float32)\n",
      "100 average_loss tf.Tensor(1.7090285, shape=(), dtype=float32)\n",
      "200 average_loss tf.Tensor(1.5193205, shape=(), dtype=float32)\n",
      "300 average_loss tf.Tensor(1.4650822, shape=(), dtype=float32)\n",
      "400 average_loss tf.Tensor(1.3945763, shape=(), dtype=float32)\n",
      "epoch 3\n",
      "0 average_loss tf.Tensor(1.4637356, shape=(), dtype=float32)\n",
      "100 average_loss tf.Tensor(1.2442632, shape=(), dtype=float32)\n",
      "200 average_loss tf.Tensor(1.3207438, shape=(), dtype=float32)\n",
      "300 average_loss tf.Tensor(1.2408967, shape=(), dtype=float32)\n",
      "400 average_loss tf.Tensor(1.2203016, shape=(), dtype=float32)\n",
      "epoch 4\n",
      "0 average_loss tf.Tensor(1.2379513, shape=(), dtype=float32)\n",
      "100 average_loss tf.Tensor(1.0098835, shape=(), dtype=float32)\n",
      "200 average_loss tf.Tensor(1.2398269, shape=(), dtype=float32)\n",
      "300 average_loss tf.Tensor(1.042353, shape=(), dtype=float32)\n",
      "400 average_loss tf.Tensor(1.113796, shape=(), dtype=float32)\n",
      "test acc 0.7861\n"
     ]
    }
   ],
   "source": [
    "model = SimpleSequential([\n",
    "    SimpleDense(28*28,512,tf.nn.relu), \n",
    "    SimpleDense(512,10,tf.nn.softmax)])\n",
    "batch_gen = BatchGenerator(train_images, train_labels)\n",
    "for epoch in range(5):\n",
    "    print('epoch', epoch)\n",
    "    for i, batch in enumerate(range(batch_gen.n_batches)):\n",
    "        images_batch, labels_batch = batch_gen.next()\n",
    "        average_loss = one_training_step(model, images_batch, labels_batch)\n",
    "        if i%100 == 0:\n",
    "            print(i, 'average_loss', average_loss)\n",
    "            \n",
    "predictions = model(test_images)\n",
    "predictions = predictions.numpy()\n",
    "predicted_labels = predictions.argmax(axis=1)\n",
    "print('test acc', (predicted_labels==test_labels).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7237969f",
   "metadata": {},
   "source": [
    "Initial test acc 0.7627\n",
    "\n",
    "test acc 0.7861 with shuffle but I think acc varies by +/- 2% anyway"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
