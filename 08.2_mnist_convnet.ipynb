{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f11b96cc",
   "metadata": {},
   "source": [
    "# MNIST convnet\n",
    "\n",
    "This notebook will re-create the pytorch model and training in https://github.com/pete88b/data-science/blob/master/myohddac/notebooks/010_mnist_training.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e65fa9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from utils.all import *\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f03c03fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28, 28, 1)).astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28, 28, 1)).astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6209850",
   "metadata": {},
   "source": [
    "Here's the pytorch model that we want to re-produce\n",
    "\n",
    "```\n",
    "def conv_block(in_channels, out_channels, padding=1):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, 3, padding=padding),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d((2,2)))\n",
    "\n",
    "def fc_block(in_features, out_features):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(in_features, out_features),\n",
    "        nn.ReLU())\n",
    "\n",
    "def new_model(c_out=10):\n",
    "    return nn.Sequential(\n",
    "        conv_block(3, 32, padding=2),\n",
    "        conv_block(32, 32),\n",
    "        conv_block(32, 32),\n",
    "        nn.Flatten(),\n",
    "        fc_block(288, 84),\n",
    "        nn.Linear(84, c_out))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e733002e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_model():\n",
    "    inputs = layers.Input(shape=train_images.shape[1:])\n",
    "    x = layers.Conv2D(filters=32, kernel_size=3, padding='same', activation='relu')(inputs)\n",
    "    x = layers.MaxPool2D(2)(x)\n",
    "    x = layers.Conv2D(filters=32, kernel_size=3, padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPool2D(2)(x)\n",
    "    x = layers.Conv2D(filters=32, kernel_size=3, padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPool2D(2)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(units=84, activation='relu')(x)\n",
    "    outputs = layers.Dense(units=10, activation='softmax')(x)\n",
    "    return keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc0e94f",
   "metadata": {},
   "source": [
    "We see fewer params in the 1st conv layer as we're using 1 channel input for the keras model.\n",
    "\n",
    "We used `padding=2` for the 1st conv in the pytorch model, which we can replicate by running\n",
    "```\n",
    "train_images, test_images = [np.pad(i, [[0,0], [1,1], [1,1], [0,0]]) for i in [train_images, test_images]]\n",
    "```\n",
    "before we create the model.\n",
    "\n",
    "`padding=2` for the 1st conv can help if you have useful info all the way to the edges of your images (padding with reflection rather than zeros is usually best). As MNIST images are centered, the edge pixels are all zero - which is probably why padding the images doesn't make a difference to accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "067e955d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 7, 7, 32)          9248      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 3, 3, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 288)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 84)                24276     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                850       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 43,942\n",
      "Trainable params: 43,942\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = new_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "575169e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 48s 25ms/step - loss: 0.1751 - accuracy: 0.9449 - val_loss: 0.0538 - val_accuracy: 0.9813\n",
      "CPU times: total: 3min 23s\n",
      "Wall time: 48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = new_model()\n",
    "model.compile(optimizer='rmsprop', # increasing learning rate doesn't seem to help\n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(train_images, train_labels, \n",
    "                    validation_data=[test_images, test_labels], \n",
    "                    batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76aea93d",
   "metadata": {},
   "source": [
    "We probably need one cycle to get the same accuracy as the fastai trained model, but reducing batch size helps;\n",
    "- `batch_size=128` gives us `val_accuracy: 0.9776`\n",
    "    - 469 training steps in 21s (Training on a CPU)\n",
    "- `batch_size=32` gives us `val_accuracy: 0.9858`\n",
    "    - 1875 training steps in 26s\n",
    "    \n",
    "Note: fastai also uses Adam by default, but we're sticking with the keras recommendation of rmsprop.\n",
    "\n",
    "You can get this model to >99% validation accuracy by training for 5 epochs with batch size 64."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d309e9",
   "metadata": {},
   "source": [
    "Most of the time, I think normalizing images helps when training a model from random weights - not sure why, but we seem to get better MNIST results when pixel values are scaled to be between 0 and 1.\n",
    "\n",
    "If we want to normalize inputs, we could do something like &darr;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45e4f86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "mean, std = train_images.mean(), train_images.std()\n",
    "def prep_images(images):\n",
    "    images = images[..., None].astype(\"float32\")\n",
    "    return (images - mean) / std\n",
    "train_images, test_images = prep_images(train_images), prep_images(test_images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
