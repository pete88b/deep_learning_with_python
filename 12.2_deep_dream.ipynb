{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/chapter12_part02_deep-dream.ipynb\n",
    "\n",
    "best results 300x300 -> 400x400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp /tmp/.keras/datasets/coast.jpg data/images/deep_dream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-ucun_roc because the default path (/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://img-datasets.s3.amazonaws.com/coast.jpg\n",
      "442368/440742 [==============================] - 0s 1us/step\n",
      "450560/440742 [==============================] - 0s 1us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1b23ae8f70>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "base_image_path = keras.utils.get_file(\n",
    "    \"coast.jpg\", origin=\"https://img-datasets.s3.amazonaws.com/coast.jpg\")\n",
    "\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(keras.utils.load_img(base_image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 3s 0us/step\n",
      "87924736/87910968 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import inception_v3\n",
    "model = inception_v3.InceptionV3(weights=\"imagenet\", include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_settings = {\n",
    "    \"mixed4\": 1.0,\n",
    "    \"mixed5\": 1.5,\n",
    "    \"mixed6\": 2.0,\n",
    "    \"mixed7\": 2.5,\n",
    "}\n",
    "outputs_dict = dict(\n",
    "    [\n",
    "        (layer.name, layer.output)\n",
    "        for layer in [model.get_layer(name) for name in layer_settings.keys()]\n",
    "    ]\n",
    ")\n",
    "feature_extractor = keras.Model(inputs=model.inputs, outputs=outputs_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(input_image):\n",
    "    features = feature_extractor(input_image)\n",
    "    loss = tf.zeros(shape=())\n",
    "    for name in features.keys():\n",
    "        coeff = layer_settings[name]\n",
    "        activation = features[name]\n",
    "        loss += coeff * tf.reduce_mean(tf.square(activation[:, 2:-2, 2:-2, :]))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "@tf.function\n",
    "def gradient_ascent_step(image, learning_rate):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(image)\n",
    "        loss = compute_loss(image)\n",
    "    grads = tape.gradient(loss, image)\n",
    "    grads = tf.math.l2_normalize(grads)\n",
    "    image += learning_rate * grads\n",
    "    return loss, image\n",
    "\n",
    "\n",
    "def gradient_ascent_loop(image, iterations, learning_rate, max_loss=None):\n",
    "    for i in range(iterations):\n",
    "        loss, image = gradient_ascent_step(image, learning_rate)\n",
    "        if max_loss is not None and loss > max_loss:\n",
    "            break\n",
    "        print(f\"... Loss value at step {i}: {loss:.2f}\")\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 20.\n",
    "num_octave = 3\n",
    "octave_scale = 1.4\n",
    "iterations = 30\n",
    "max_loss = 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    img = keras.utils.load_img(image_path)\n",
    "    img = keras.utils.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = keras.applications.inception_v3.preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "def deprocess_image(img):\n",
    "    img = img.reshape((img.shape[1], img.shape[2], 3))\n",
    "    img /= 2.0\n",
    "    img += 0.5\n",
    "    img *= 255.\n",
    "    img = np.clip(img, 0, 255).astype(\"uint8\")\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing octave 0 with shape (459, 612)\n",
      "... Loss value at step 0: 0.80\n",
      "... Loss value at step 1: 1.07\n",
      "... Loss value at step 2: 1.44\n",
      "... Loss value at step 3: 1.82\n",
      "... Loss value at step 4: 2.17\n",
      "... Loss value at step 5: 2.49\n",
      "... Loss value at step 6: 2.83\n",
      "... Loss value at step 7: 3.20\n",
      "... Loss value at step 8: 3.55\n",
      "... Loss value at step 9: 3.92\n",
      "... Loss value at step 10: 4.30\n",
      "... Loss value at step 11: 4.67\n",
      "... Loss value at step 12: 4.98\n",
      "... Loss value at step 13: 5.41\n",
      "... Loss value at step 14: 5.73\n",
      "... Loss value at step 15: 6.08\n",
      "... Loss value at step 16: 6.43\n",
      "... Loss value at step 17: 6.82\n",
      "... Loss value at step 18: 7.15\n",
      "... Loss value at step 19: 7.54\n",
      "... Loss value at step 20: 7.77\n",
      "... Loss value at step 21: 8.14\n",
      "... Loss value at step 22: 8.41\n",
      "... Loss value at step 23: 8.73\n",
      "... Loss value at step 24: 9.00\n",
      "... Loss value at step 25: 9.36\n",
      "... Loss value at step 26: 9.62\n",
      "... Loss value at step 27: 9.90\n",
      "... Loss value at step 28: 10.12\n",
      "... Loss value at step 29: 10.46\n",
      "Processing octave 1 with shape (642, 857)\n",
      "... Loss value at step 0: 1.62\n",
      "... Loss value at step 1: 2.68\n",
      "... Loss value at step 2: 3.49\n",
      "... Loss value at step 3: 4.10\n",
      "... Loss value at step 4: 4.65\n",
      "... Loss value at step 5: 5.12\n",
      "... Loss value at step 6: 5.59\n",
      "... Loss value at step 7: 5.99\n",
      "... Loss value at step 8: 6.41\n",
      "... Loss value at step 9: 6.78\n",
      "... Loss value at step 10: 7.18\n",
      "... Loss value at step 11: 7.52\n",
      "... Loss value at step 12: 7.89\n",
      "... Loss value at step 13: 8.19\n",
      "... Loss value at step 14: 8.55\n",
      "... Loss value at step 15: 8.77\n",
      "... Loss value at step 16: 9.12\n",
      "... Loss value at step 17: 9.40\n",
      "... Loss value at step 18: 9.71\n",
      "... Loss value at step 19: 10.01\n",
      "... Loss value at step 20: 10.18\n",
      "... Loss value at step 21: 10.57\n",
      "... Loss value at step 22: 10.76\n",
      "... Loss value at step 23: 11.17\n",
      "... Loss value at step 24: 11.25\n",
      "... Loss value at step 25: 11.70\n",
      "... Loss value at step 26: 11.88\n",
      "... Loss value at step 27: 12.16\n",
      "... Loss value at step 28: 12.39\n",
      "... Loss value at step 29: 12.69\n",
      "Processing octave 2 with shape (900, 1200)\n",
      "... Loss value at step 0: 1.43\n",
      "... Loss value at step 1: 2.23\n",
      "... Loss value at step 2: 2.88\n",
      "... Loss value at step 3: 3.37\n",
      "... Loss value at step 4: 3.82\n",
      "... Loss value at step 5: 4.24\n",
      "... Loss value at step 6: 4.66\n",
      "... Loss value at step 7: 5.08\n",
      "... Loss value at step 8: 5.45\n",
      "... Loss value at step 9: 5.82\n",
      "... Loss value at step 10: 6.16\n",
      "... Loss value at step 11: 6.52\n",
      "... Loss value at step 12: 6.80\n",
      "... Loss value at step 13: 7.22\n",
      "... Loss value at step 14: 7.45\n",
      "... Loss value at step 15: 7.81\n",
      "... Loss value at step 16: 8.11\n",
      "... Loss value at step 17: 8.43\n",
      "... Loss value at step 18: 8.72\n",
      "... Loss value at step 19: 9.12\n",
      "... Loss value at step 20: 9.21\n",
      "... Loss value at step 21: 9.81\n",
      "... Loss value at step 22: 9.81\n",
      "... Loss value at step 23: 10.46\n",
      "... Loss value at step 24: 10.43\n",
      "... Loss value at step 25: 10.99\n",
      "... Loss value at step 26: 11.00\n",
      "... Loss value at step 27: 11.50\n",
      "... Loss value at step 28: 11.72\n",
      "... Loss value at step 29: 12.16\n"
     ]
    }
   ],
   "source": [
    "original_img = preprocess_image(base_image_path)\n",
    "original_shape = original_img.shape[1:3]\n",
    "\n",
    "successive_shapes = [original_shape]\n",
    "for i in range(1, num_octave):\n",
    "    shape = tuple([int(dim / (octave_scale ** i)) for dim in original_shape])\n",
    "    successive_shapes.append(shape)\n",
    "successive_shapes = successive_shapes[::-1]\n",
    "\n",
    "shrunk_original_img = tf.image.resize(original_img, successive_shapes[0])\n",
    "\n",
    "img = tf.identity(original_img)\n",
    "for i, shape in enumerate(successive_shapes):\n",
    "    print(f\"Processing octave {i} with shape {shape}\")\n",
    "    img = tf.image.resize(img, shape)\n",
    "    img = gradient_ascent_loop(\n",
    "        img, iterations=iterations, learning_rate=step, max_loss=max_loss\n",
    "    )\n",
    "    upscaled_shrunk_original_img = tf.image.resize(shrunk_original_img, shape)\n",
    "    same_size_original = tf.image.resize(original_img, shape)\n",
    "    lost_detail = same_size_original - upscaled_shrunk_original_img\n",
    "    img += lost_detail\n",
    "    shrunk_original_img = tf.image.resize(original_img, shape)\n",
    "\n",
    "keras.utils.save_img(\"data/images/deep_dream/dream.png\", deprocess_image(img.numpy()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
